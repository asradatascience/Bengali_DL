{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "loading model_testing",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "491222456ce148eea068d6a554423ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2b9cfdf0c468475e8baf691c090db430",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_940138ca5b6047b8b6b8b5d5e3f7941a",
              "IPY_MODEL_9842df6a35fa4e4fa441315832ee45d5"
            ]
          }
        },
        "2b9cfdf0c468475e8baf691c090db430": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "940138ca5b6047b8b6b8b5d5e3f7941a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a353bc964fbc4887839e0bdbdc0895ca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a4bebfceec742cc9baf45b480638f75"
          }
        },
        "9842df6a35fa4e4fa441315832ee45d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d1ff084b84524b7ba73d1cee15e6314a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "8it [00:03,  2.22it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d8de62ef90b144fa9f6567d4f9916bf7"
          }
        },
        "a353bc964fbc4887839e0bdbdc0895ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a4bebfceec742cc9baf45b480638f75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d1ff084b84524b7ba73d1cee15e6314a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d8de62ef90b144fa9f6567d4f9916bf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZYnPhc6n7iW",
        "colab_type": "code",
        "outputId": "61b9ac7b-c8e0-4067-d5fb-f781ad5a11af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "%matplotlib inline\n",
        "!pip install livelossplot\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from skimage import io, transform\n",
        "from tqdm import tqdm_notebook\n",
        "from livelossplot import PlotLosses\n",
        "from datetime import datetime\n",
        "# Ignore warnings\n",
        "import warnings,os\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting livelossplot\n",
            "  Downloading https://files.pythonhosted.org/packages/8e/f6/0618c30078f9c1e4b2cd84f1ea6bb70c6615070468b75b0d934326107bcd/livelossplot-0.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from livelossplot) (3.1.2)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from livelossplot) (5.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (2.6.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (2.4.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (1.17.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot) (1.1.0)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.5.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (5.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (2.10.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.3.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (5.3.4)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (0.8.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (5.0.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot) (4.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->livelossplot) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->livelossplot) (42.0.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (2.1.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (3.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.6.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.4.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot) (1.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->livelossplot) (1.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->notebook->livelossplot) (5.5.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.1->notebook->livelossplot) (4.4.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook->livelossplot) (17.0.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->livelossplot) (0.6.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook->livelossplot) (2.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook->livelossplot) (0.5.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot) (4.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook->livelossplot) (0.1.8)\n",
            "Installing collected packages: livelossplot\n",
            "Successfully installed livelossplot-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdZ2Kx5Jtq5A",
        "colab_type": "code",
        "outputId": "68a8f2a8-0a6f-4ca5-96ff-27802cc5952f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay7cQGvEn7ik",
        "colab_type": "code",
        "outputId": "0375948c-4cb6-4f29-9dea-b128c1dc761f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/Bengali_Dataset',force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /Bengali_Dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vxo15xOgxKgL",
        "colab_type": "code",
        "outputId": "70f593d2-1836-49f5-b859-7cc73f4d04b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls \"/Bengali_Dataset/My Drive/Bengali\"\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "images_unzipped.csv\tmodel.pth      train.csv     train.zip\n",
            "images_unzipped.gsheet\tpytorch.ipynb  train_subset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIi85Sgt5BkF",
        "colab_type": "code",
        "outputId": "84890ee8-84e3-4f25-8a53-2eba6d44af3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "root_path = '/Bengali_Dataset/My Drive/Bengali/'\n",
        "print(type(root_path))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g6hjvddpQDu",
        "colab_type": "code",
        "outputId": "49249403-0190-47b3-bd00-aa75e71d1ea1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df=pd.read_csv(root_path + \"train.csv\")\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>grapheme_root</th>\n",
              "      <th>vowel_diacritic</th>\n",
              "      <th>consonant_diacritic</th>\n",
              "      <th>grapheme</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Train_0</td>\n",
              "      <td>15</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>ক্ট্রো</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Train_1</td>\n",
              "      <td>159</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>হ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Train_2</td>\n",
              "      <td>22</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>খ্রী</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Train_3</td>\n",
              "      <td>53</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>র্টি</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Train_4</td>\n",
              "      <td>71</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>থ্রো</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
              "0  Train_0             15                9                    5   ক্ট্রো\n",
              "1  Train_1            159                0                    0        হ\n",
              "2  Train_2             22                3                    5     খ্রী\n",
              "3  Train_3             53                2                    2     র্টি\n",
              "4  Train_4             71                9                    5     থ্রো"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l3X38APn7ip",
        "colab_type": "code",
        "outputId": "0017292e-f1e5-4080-db95-273e5edf68c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "label1_num = df['grapheme_root'].max()+1\n",
        "label2_num = df['vowel_diacritic'].max()+1\n",
        "label3_num = df['consonant_diacritic'].max()+1\n",
        "\n",
        "print(label1_num)\n",
        "print(label2_num)\n",
        "print(label3_num)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "168\n",
            "11\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P7lLcg8-BmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = 0.06922848809290576\n",
        "std = 0.20515700083327537"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0WjJO3Qn7it",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ToTensor(object):\n",
        "    \"\"\"Convert ndarrays in sample to Tensors. Also normalize the images\"\"\"\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, labels = sample['image'], sample['labels']\n",
        "        image = (image - 255)/255\n",
        "        image = (image - mean)/std\n",
        "        image = torch.from_numpy(image)\n",
        "        \n",
        "        image = image[np.newaxis,...]\n",
        "        return {'image': image,\n",
        "                'labels': torch.from_numpy(np.array(labels))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuzzrdvO7Ho6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "csv_dir=\"/Bengali_Dataset/My Drive/Bengali/train.csv\"\n",
        "root_dir=root_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EvHYT7Rn7iw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class bengalidataset(Dataset):\n",
        "    def __init__(self,csv_dir,root_dir,transform=None):\n",
        "        self.csv_dir = csv_dir\n",
        "        self.olddata = pd.read_csv(csv_dir)\n",
        "        self.data = []\n",
        "        self.root_dir = root_dir\n",
        "        for index in range(len(self.olddata)):\n",
        "          # print(index)\n",
        "          filename= f'{self.root_dir}train_subset/train/{self.olddata.iloc[index,0]}.png'\n",
        "          if(not os.path.exists(filename)): continue\n",
        "          \n",
        "          self.data.append(list(self.olddata.iloc[index]))\n",
        "\n",
        "        self.data = pd.DataFrame(self.data,columns=['Image ID','label1','label2','label3','Grapheme'])\n",
        "\n",
        "        print(self.data.shape)\n",
        "        #self.data.to_csv('/Bengali_Dataset/My Drive/Bengali/images_unzipped.csv') #Don't forget to add '.csv' at the end of the path\n",
        "\n",
        "        #print(self.data.head())\n",
        "\n",
        "        self.transform = transform\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "        \n",
        "    def __getitem__(self,index=0):\n",
        "        '''\n",
        "        Returns image, \n",
        "            \n",
        "            label is,\n",
        "            \n",
        "            grapheme_root          15\n",
        "            vowel_diacritic         9\n",
        "            consonant_diacritic     5\n",
        "        '''\n",
        "        \n",
        "        if torch.is_tensor(index):\n",
        "            index = index.tolist()\n",
        "            \n",
        "        \n",
        "        img_name = Path(f'{self.root_dir}train_subset/train/{self.data.iloc[index,0]}.png')\n",
        "        img = io.imread(img_name)\n",
        "        labels = self.data.iloc[index,1:4]\n",
        "        \n",
        "        labels = list(labels)\n",
        "        \n",
        "        sample = {\"image\":img,\"labels\":labels}        \n",
        "        \n",
        "        \n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "\n",
        "        \n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8t3vK-gn7iz",
        "colab_type": "code",
        "outputId": "44172970-c257-48b0-e2dd-780ecf999d57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Dataset creation for visualization purpose.\n",
        "datast = bengalidataset(csv_dir=Path(root_path + \"train.csv\"),root_dir=root_path)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1851, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxEWWYd_dO8e",
        "colab_type": "code",
        "outputId": "0f8a74dc-44b1-4058-d250-e6ed8368c566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "datast = bengalidataset(csv_dir=Path(root_path + \"train.csv\"),root_dir=root_path,transform=transforms.Compose([ToTensor()]))\n",
        "print(type(datast))\n",
        "testset=datast\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1851, 5)\n",
            "<class '__main__.bengalidataset'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAtQg3Omn7i6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs=256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNuHWpdsn7i8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=bs,\n",
        "                                         shuffle=True, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjLfXPI9n7i-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NNet(nn.Module):\n",
        "    def __init__(self,label1_num,label2_num,label3_num):\n",
        "        super(NNet,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1,32,5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32,64,5)\n",
        "        self.conv3 = nn.Conv2d(64,128,5)    \n",
        "        self.fc1 = nn.Linear(128*12*12,label1_num)\n",
        "        self.fc2 = nn.Linear(128*12*12,label2_num)\n",
        "        self.fc3 = nn.Linear(128*12*12,label3_num)\n",
        "        \n",
        "        softmax = nn.Softmax(dim=1) \n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.pool(x)\n",
        "#         print(x.shape)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool(x)\n",
        "#         print(x.shape)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.pool(x)\n",
        "        bss = x.shape[0]     \n",
        "        x = x.reshape(bss,-1)\n",
        "        \n",
        "        l1 = self.fc1(x)\n",
        "        l2 = self.fc2(x)\n",
        "        l3 = self.fc3(x)\n",
        "        \n",
        "        #print(l1.shape) #expecting batch_size*168, 8 for no.of images and 168 is count of grapheme_roots\n",
        "        #print(l2.shape) #expecting batch_zsize*11\n",
        "        #print(l3.shape) #expecting batchsize*7 \n",
        "\n",
        "        grapheme_list=l1.cpu().data.numpy().argmax(axis=1)\n",
        "        vowel_list=l2.cpu().data.numpy().argmax(axis=1)\n",
        "        consonant_list=l3.cpu().data.numpy().argmax(axis=1)\n",
        "\n",
        "        oldl1=l1\n",
        "        oldl2=l2\n",
        "        oldl3=l3\n",
        "\n",
        "\n",
        "        \n",
        "        return oldl1, oldl2, oldl3,grapheme_list,vowel_list,consonant_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lpoz-0Cd1t8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH=Path(root_path + \"model.pth \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-qBHSjjpbXR",
        "colab_type": "code",
        "outputId": "1aabf919-7aef-4cc8-8744-b8abb260354f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# train on cuda if available\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "nnet = NNet(label1_num,label2_num,label3_num)\n",
        "nnet.load_state_dict(torch.load('/Bengali_Dataset/My Drive/Bengali/model.pth'))\n",
        "\n",
        "nnet.to(device)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NNet(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=18432, out_features=168, bias=True)\n",
              "  (fc2): Linear(in_features=18432, out_features=11, bias=True)\n",
              "  (fc3): Linear(in_features=18432, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA5i6WhHqDML",
        "colab_type": "code",
        "outputId": "6851639f-d4a2-413d-e03a-d4148474ba9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "nnet.fc1.weight\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0024,  0.0033,  0.0054,  ...,  0.0084,  0.0135,  0.0025],\n",
              "        [-0.0044, -0.0043,  0.0016,  ..., -0.0013, -0.0089, -0.0068],\n",
              "        [-0.0014,  0.0056,  0.0033,  ..., -0.0051,  0.0084, -0.0048],\n",
              "        ...,\n",
              "        [ 0.0075, -0.0013, -0.0005,  ...,  0.0033,  0.0148,  0.0086],\n",
              "        [-0.0006, -0.0007, -0.0048,  ...,  0.0023,  0.0077,  0.0003],\n",
              "        [-0.0070, -0.0019,  0.0028,  ...,  0.0161,  0.0166,  0.0021]],\n",
              "       device='cuda:0', requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyhHfKSPR4gc",
        "colab_type": "code",
        "outputId": "e53bdc23-38e2-45e6-9113-8e16de44a24a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "print(testset[1])\n",
        "print(len(testset))\n",
        "print(testset[i])\n",
        "print(type(testset[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'image': tensor([[[-0.3183, -0.3183, -0.3183,  ..., -0.3183, -0.3183, -0.3183],\n",
            "         [-0.3183, -0.3183, -0.3183,  ..., -0.3183, -0.3183, -0.3183],\n",
            "         [-0.3183, -0.3183, -0.3183,  ..., -0.3183, -0.3183, -0.3183],\n",
            "         ...,\n",
            "         [-0.3183, -0.3183, -0.3183,  ..., -0.3183, -0.3183, -0.3183],\n",
            "         [-0.3183, -0.3183, -0.3183,  ..., -0.3183, -0.3183, -0.3183],\n",
            "         [-0.3183, -0.3183, -0.3183,  ..., -0.3183, -0.3183, -0.3183]]],\n",
            "       dtype=torch.float64), 'labels': tensor([159,   0,   0])}\n",
            "1851\n",
            "{'image': tensor([[[-0.3183, -0.3183, -0.3183,  ..., -0.3183, -0.3183, -0.3183],\n",
            "         [-0.3183, -0.3183, -0.3183,  ..., -0.3183, -0.3183, -0.3183],\n",
            "         [-0.3183, -0.3183, -0.3183,  ..., -0.3183, -0.3183, -0.3183],\n",
            "         ...,\n",
            "         [-0.3183, -0.3183, -0.3183,  ..., -0.3183, -0.3183, -0.3183],\n",
            "         [-0.3183, -0.3183, -0.3183,  ..., -0.3183, -0.3183, -0.3183],\n",
            "         [-0.3183, -0.3183, -0.3183,  ..., -0.3183, -0.3183, -0.3183]]],\n",
            "       dtype=torch.float64), 'labels': tensor([13,  1,  4])}\n",
            "<class 'dict'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar7o1YkANtVU",
        "colab_type": "code",
        "outputId": "9c47cd62-eb6a-4476-e1ef-d3e5b192de0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "491222456ce148eea068d6a554423ba3",
            "2b9cfdf0c468475e8baf691c090db430",
            "940138ca5b6047b8b6b8b5d5e3f7941a",
            "9842df6a35fa4e4fa441315832ee45d5",
            "a353bc964fbc4887839e0bdbdc0895ca",
            "7a4bebfceec742cc9baf45b480638f75",
            "d1ff084b84524b7ba73d1cee15e6314a",
            "d8de62ef90b144fa9f6567d4f9916bf7"
          ]
        }
      },
      "source": [
        "grapheme_overall=0\n",
        "vowel_overall=0\n",
        "consonant_overall=0\n",
        "overall_overall=0\n",
        "\n",
        "target_overall=0\n",
        "\n",
        "\n",
        "for step,batch in tqdm_notebook(enumerate(testloader)):\n",
        "  grapheme_counter=0\n",
        "  vowel_counter=0\n",
        "  consonant_counter=0\n",
        "  overall_counter=0\n",
        "\n",
        "  try:\n",
        "    label1, label2, label3,grapheme_list,vowel_list,consonant_list = nnet(batch['image'].float().cuda())\n",
        "  except Exception as e:\n",
        "    print('working?', e)\n",
        "  \n",
        "  labels=batch['labels'].cuda()\n",
        "  targ_label1=labels[:,0]\n",
        "  targ_label2=labels[:,1]\n",
        "  targ_label3=labels[:,2]\n",
        "  \n",
        "  target_overall=target_overall+len(grapheme_list)\n",
        "  for i in range(len(grapheme_list)):\n",
        "    if grapheme_list[i] == targ_label1[i]: ##confirm if targ_label 1 has all batc size numbers of just 1\n",
        "      grapheme_counter=grapheme_counter+1\n",
        "      grapheme_overall=grapheme_overall+1\n",
        "    if vowel_list[i]==targ_label2[i]:\n",
        "      vowel_counter=vowel_counter+1\n",
        "      vowel_overall=vowel_overall+1\n",
        "    if consonant_list[i]==targ_label3[i]:\n",
        "      consonant_counter=consonant_counter+1\n",
        "      consonant_overall=consonant_overall+1\n",
        "    if grapheme_list[i] == targ_label1[i] and vowel_list[i]==targ_label2[i] and consonant_list[i]==targ_label3[i]:\n",
        "      overall_counter=overall_counter+1\n",
        "      overall_overall=overall_overall+1\n",
        "\n",
        "\n",
        "  if(step>0):\n",
        "      print(\"***.............................**\")\n",
        "      print(f\"step is..{step}\")\n",
        "      print(f\"count of images..{len(targ_label1)}\")\n",
        "      print(f\"grapheme counter..{grapheme_counter}\")\n",
        "      print(f\"grapheme_counter----  {round((grapheme_counter/len(targ_label1))*100,2)}%\")\n",
        "      print(f\"vowel_counter----  {round((vowel_counter/len(targ_label1))*100,2)}%\")\n",
        "      print(f\"consonant_counter----  {round((consonant_counter/len(targ_label1))*100,2)}%\")\n",
        "      print(f\"overall_counter----  {round((overall_counter/len(targ_label1))*100,2)}%\")\n",
        "\n",
        "print(\"*****----------Overall----------------***************\")\n",
        "print(f\"overall_counter...{overall_overall}\")\n",
        "print(f\"overall image count...{target_overall}\")\n",
        "print(f\"grapheme_overall_counter----  {round((grapheme_overall/(target_overall))*100,2)}%\")\n",
        "print(f\"vowel_counter----  {round((vowel_overall/(target_overall))*100,2)}%\")\n",
        "print(f\"consonant_counter----  {round((consonant_overall/(target_overall))*100,2)}%\")\n",
        "print(f\"overall_counter----  {round((overall_overall/(target_overall))*100,2)}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "491222456ce148eea068d6a554423ba3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "***.............................**\n",
            "step is..1\n",
            "count of images..256\n",
            "grapheme counter..240\n",
            "grapheme_counter----  93.75%\n",
            "vowel_counter----  95.31%\n",
            "consonant_counter----  92.58%\n",
            "overall_counter----  83.2%\n",
            "***.............................**\n",
            "step is..2\n",
            "count of images..256\n",
            "grapheme counter..239\n",
            "grapheme_counter----  93.36%\n",
            "vowel_counter----  96.09%\n",
            "consonant_counter----  92.97%\n",
            "overall_counter----  83.59%\n",
            "***.............................**\n",
            "step is..3\n",
            "count of images..256\n",
            "grapheme counter..234\n",
            "grapheme_counter----  91.41%\n",
            "vowel_counter----  95.7%\n",
            "consonant_counter----  92.97%\n",
            "overall_counter----  81.64%\n",
            "***.............................**\n",
            "step is..4\n",
            "count of images..256\n",
            "grapheme counter..239\n",
            "grapheme_counter----  93.36%\n",
            "vowel_counter----  94.92%\n",
            "consonant_counter----  94.53%\n",
            "overall_counter----  83.2%\n",
            "***.............................**\n",
            "step is..5\n",
            "count of images..256\n",
            "grapheme counter..239\n",
            "grapheme_counter----  93.36%\n",
            "vowel_counter----  96.48%\n",
            "consonant_counter----  94.53%\n",
            "overall_counter----  85.55%\n",
            "***.............................**\n",
            "step is..6\n",
            "count of images..256\n",
            "grapheme counter..248\n",
            "grapheme_counter----  96.88%\n",
            "vowel_counter----  96.09%\n",
            "consonant_counter----  93.36%\n",
            "overall_counter----  87.5%\n",
            "***.............................**\n",
            "step is..7\n",
            "count of images..59\n",
            "grapheme counter..54\n",
            "grapheme_counter----  91.53%\n",
            "vowel_counter----  94.92%\n",
            "consonant_counter----  91.53%\n",
            "overall_counter----  79.66%\n",
            "*****----------Overall----------------***************\n",
            "overall_counter...1551\n",
            "overall image count...1851\n",
            "grapheme_overall_counter----  93.46%\n",
            "vowel_counter----  95.68%\n",
            "consonant_counter----  93.41%\n",
            "overall_counter----  83.79%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2jW69x1gArE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}